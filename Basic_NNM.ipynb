{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOU0KazNY2a9IX8GmicP7x3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/obedest/DeepLearning-with-PyTorch---Codemy.com/blob/main/Basic_NNM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "E8hTrYAUIpTx"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F # will help move data forward in our fuction"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create a Model Class that inherits nn.Module\n",
        "class Model(nn.Module):\n",
        "  # input layer (4 features of the flower) -> hidden layer 1 (with some number of neurons) -> hidden layer 2 -> output (3 classes of iris flowers)\n",
        "  def __init__(self, in_features=4, h1=8, h2=9, out_features=3): # 8 and 9 are random numbers\n",
        "  # h1 and h2 in Model class's __init__ method  represent the number of neurons in the hidden layers.\n",
        "  # What they affect: The values of h1 and h2 significantly affect the following:\n",
        "  # Model Capacity: They determine the number of neurons in each hidden layer. More neurons in a layer generally mean the model has a higher capacity to learn complex patterns in the data.\n",
        "  # Number of Parameters: The number of neurons in a layer directly influences the number of weights and biases (parameters) in the connections between that layer and the next. More neurons mean more parameters. A model with too many parameters relative to the amount of training data can lead to overfitting (performing well on training data but poorly on unseen data).\n",
        "  # Computational Cost: More neurons mean more calculations are performed during the forward and backward passes, increasing the training and inference time.\n",
        "  # Learning Ability: The right number of neurons in the hidden layers allows the model to capture the underlying structure of the data effectively. Too few neurons might prevent the model from learning complex relationships (underfitting), while too many can lead to overfitting.\n",
        "  # How to choose them: Choosing the optimal number of neurons in hidden layers (h1, h2, etc.) is a crucial part of designing a neural network architecture. There's no single formula for this; it often involves:\n",
        "  # Experimentation: Trying different numbers of neurons and evaluating the model's performance on a validation set.\n",
        "  # Heuristics: Starting with values between the input and output layer sizes, or using powers of 2 (e.g., 16, 32, 64).\n",
        "  # Considering the complexity of the problem: More complex problems generally require more neurons or layers.\n",
        "  # Considering the size of the dataset: With limited data, you might need fewer neurons to avoid overfitting.\n",
        "  # In your current code, h1=8 and h2=9 are small, which is suitable for a relatively simple dataset like the Iris dataset. For more complex tasks, you would likely need larger hidden layers.\n",
        "    super().__init__() # instantiale our nn.Module\n",
        "    self.fc1 = nn.Linear(in_features, h1) # fc stands for fully connected\n",
        "    self.fc2 = nn.Linear(h1, h2)\n",
        "    self.out = nn.Linear(h2, out_features)\n",
        "    # nn.Linear is used to create a \"fully connected\" or \"dense\" layer in a neural network. This type of layer performs a linear transformation on the input data: output = input * weights + bias.\n",
        "    # What it does: It takes an input tensor and applies a learned set of weights and biases to produce an output tensor. The in_features argument specifies the number of input features (the size of the input tensor), and the out_features argument specifies the number of output features (the size of the output tensor).\n",
        "    # Other options: PyTorch's nn module offers many other types of layers depending on the task:\n",
        "    # nn.Conv2d: For convolutional layers (commonly used in image processing).\n",
        "    # nn.LSTM or nn.GRU: For recurrent layers (commonly used for sequential data like text).\n",
        "    # nn.BatchNorm1d, nn.BatchNorm2d: For batch normalization layers (help stabilize training).\n",
        "    # nn.Dropout: For dropout layers (a regularization technique to prevent overfitting).\n",
        "    # And many more!\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = F.relu(self.out(x))\n",
        "    # F.relu is the Rectified Linear Unit activation function. It's a very common choice for the hidden layers of neural networks.\n",
        "    # What it does: The ReLU function is simple: f(x) = max(0, x). It introduces non-linearity into the model. Without non-linear activation functions between layers, a neural network, no matter how many layers it has, would only be able to learn linear relationships between the input and output, which is insufficient for most complex tasks. ReLU is computationally efficient and helps with mitigating the vanishing gradient problem in deep networks.\n",
        "    # Other options: There are many other activation functions you could use:\n",
        "    # F.sigmoid: Squashes the output to a range between 0 and 1 (often used in the output layer for binary classification).\n",
        "    # F.softmax: Often used in the output layer for multi-class classification to produce a probability distribution over the classes.\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "4SDFKr4XKZtJ"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pick a manual seed for randomization (to get closer results to the orig course video)\n",
        "torch.manual_seed(41)\n",
        "# create an instance of model\n",
        "model = Model()"
      ],
      "metadata": {
        "id": "Mr2TPYxdM5WV"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "# You import pyplot to gain access to its functions for creating plots, such as plt.plot(), plt.xlabel(), plt.ylabel(), plt.title(), etc. The convention is to import it as plt for brevity.\n",
        "%matplotlib inline\n",
        "# %matplotlib inline command is used to tell the environment to display the plots generated by matplotlib directly within the notebook cells, rather than opening them in a separate window. This makes it easy to visualize your data and results directly alongside your code."
      ],
      "metadata": {
        "id": "BFlDRtvTSaS5"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "# to read_csv in my case\n",
        "# Besides CSV, pandas can read data from various other formats, including:\n",
        "# Excel files (pd.read_excel())\n",
        "# SQL databases (pd.read_sql())\n",
        "# JSON files (pd.read_json())\n",
        "# HTML tables (pd.read_html())\n",
        "# And more.\n",
        "\n",
        "# Pandas introduces two primary data structures:\n",
        "# Series: A one-dimensional labeled array capable of holding any data type (integers, strings, floating point numbers, Python objects, etc.).\n",
        "# DataFrame: A two-dimensional labeled data structure with columns of potentially different types. This is the most commonly used pandas object, similar to a spreadsheet or a SQL table. Your my_data_frame is a DataFrame.\n",
        "\n",
        "# Data Manipulation:\n",
        "# Grouping data (groupby()).\n",
        "# Aggregating data (e.g., sum(), mean(), count()).\n",
        "# Merging and joining DataFrames.\n",
        "# Reshaping data (pivot_table(), melt()).\n",
        "# Data Analysis and Exploration:\n",
        "# Calculating descriptive statistics (describe()).\n",
        "# Calculating correlations (corr()).\n",
        "# Creating frequency tables (value_counts()).\n",
        "# Applying functions to data (apply())."
      ],
      "metadata": {
        "id": "89PY-8QTSmpl"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'https://gist.githubusercontent.com/curran/a08a1080b88344b0c8a7/raw/0e7a9b0a5d22642a06d3d5b9bcbad9890c8ee534/iris.csv'\n",
        "my_data_frame = pd.read_csv(url)"
      ],
      "metadata": {
        "id": "Y9Lidrd5Sqr3"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# my_data_frame.head() # get the first 5 rows\n",
        "# my_data_frame.tail() # the last 5\n",
        "\n",
        "# Both .head() and .tail() are indeed methods that come from the pandas library. They are methods of pandas DataFrame and Series objects.\n",
        "\n",
        "# .head(): This method returns the first n rows of a DataFrame or Series. By default, it returns the first 5 rows, but you can specify a different number by passing an integer argument (e.g., my_data_frame.head(10) would return the first 10 rows).\n",
        "# .tail(): This method returns the last n rows of a DataFrame or Series. Similar to .head(), it returns the last 5 rows by default, and you can specify a different number."
      ],
      "metadata": {
        "id": "Cy14_ZoLTCbA"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# change last column from string to integer\n",
        "my_data_frame['species'] = my_data_frame['species'].replace('setosa', 0.0)\n",
        "my_data_frame['species'] = my_data_frame['species'].replace('versicolor', 1.0)\n",
        "my_data_frame['species'] = my_data_frame['species'].replace('virginica', 2.0)\n",
        "my_data_frame\n",
        "\n",
        "# The .replace() method is also a method from the pandas library. It's a very useful method for replacing values in a DataFrame or Series.\n",
        "# The .replace() method is quite versatile and can be used to replace:\n",
        "# A single value with another single value.\n",
        "# A list of values with a single value.\n",
        "# A list of values with another list of values.\n",
        "# Using regular expressions for more complex pattern replacement."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "id": "rKsJfjAbTPgN",
        "outputId": "dce47cc4-6182-43a1-aea1-b0a7af3fab1d"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2528684802.py:4: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  my_data_frame['species'] = my_data_frame['species'].replace('virginica', 2.0)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     sepal_length  sepal_width  petal_length  petal_width  species\n",
              "0             5.1          3.5           1.4          0.2      0.0\n",
              "1             4.9          3.0           1.4          0.2      0.0\n",
              "2             4.7          3.2           1.3          0.2      0.0\n",
              "3             4.6          3.1           1.5          0.2      0.0\n",
              "4             5.0          3.6           1.4          0.2      0.0\n",
              "..            ...          ...           ...          ...      ...\n",
              "145           6.7          3.0           5.2          2.3      2.0\n",
              "146           6.3          2.5           5.0          1.9      2.0\n",
              "147           6.5          3.0           5.2          2.0      2.0\n",
              "148           6.2          3.4           5.4          2.3      2.0\n",
              "149           5.9          3.0           5.1          1.8      2.0\n",
              "\n",
              "[150 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-36301819-5f64-43f0-b709-0013e2b08216\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal_length</th>\n",
              "      <th>sepal_width</th>\n",
              "      <th>petal_length</th>\n",
              "      <th>petal_width</th>\n",
              "      <th>species</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145</th>\n",
              "      <td>6.7</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.2</td>\n",
              "      <td>2.3</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146</th>\n",
              "      <td>6.3</td>\n",
              "      <td>2.5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.9</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>6.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>6.2</td>\n",
              "      <td>3.4</td>\n",
              "      <td>5.4</td>\n",
              "      <td>2.3</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>5.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.1</td>\n",
              "      <td>1.8</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>150 rows Ã— 5 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-36301819-5f64-43f0-b709-0013e2b08216')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-36301819-5f64-43f0-b709-0013e2b08216 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-36301819-5f64-43f0-b709-0013e2b08216');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-e3eb9d16-3623-484a-b19b-fc1375bf6a57\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e3eb9d16-3623-484a-b19b-fc1375bf6a57')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-e3eb9d16-3623-484a-b19b-fc1375bf6a57 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_5cf87163-188a-41e6-a1b2-b251590596a9\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('my_data_frame')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_5cf87163-188a-41e6-a1b2-b251590596a9 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('my_data_frame');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "my_data_frame",
              "summary": "{\n  \"name\": \"my_data_frame\",\n  \"rows\": 150,\n  \"fields\": [\n    {\n      \"column\": \"sepal_length\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.8280661279778629,\n        \"min\": 4.3,\n        \"max\": 7.9,\n        \"num_unique_values\": 35,\n        \"samples\": [\n          6.2,\n          4.5,\n          5.6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sepal_width\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.4335943113621737,\n        \"min\": 2.0,\n        \"max\": 4.4,\n        \"num_unique_values\": 23,\n        \"samples\": [\n          2.3,\n          4.0,\n          3.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"petal_length\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.7644204199522617,\n        \"min\": 1.0,\n        \"max\": 6.9,\n        \"num_unique_values\": 43,\n        \"samples\": [\n          6.7,\n          3.8,\n          3.7\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"petal_width\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7631607417008414,\n        \"min\": 0.1,\n        \"max\": 2.5,\n        \"num_unique_values\": 22,\n        \"samples\": [\n          0.2,\n          1.2,\n          1.3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"species\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.8192319205190405,\n        \"min\": 0.0,\n        \"max\": 2.0,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.0,\n          1.0,\n          2.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train test split! set x, y\n",
        "X = my_data_frame.drop('species', axis = 1) # need to set axis to 1 because that's a column\n",
        "# axis = 1: This is crucial. In pandas, operations can be applied along rows (axis = 0) or columns (axis = 1). Setting axis = 1 tells pandas to drop a column (as opposed to dropping a row if you used axis = 0).\n",
        "y = my_data_frame['species']"
      ],
      "metadata": {
        "id": "wLPpQca7UPTT"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert these to numpy arrays\n",
        "X = X.values\n",
        "y = y.values\n",
        "# The .values attribute is a property of pandas DataFrames and Series. When you access .values, pandas returns the data as a NumPy array."
      ],
      "metadata": {
        "id": "SA-3gIJ3VKjT"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "ta5pmwG9WFYp"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=41) # random state part is not necessary, just to keep it similar to orig video"
      ],
      "metadata": {
        "id": "eysFFJafWkpp"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# float because x-things are all decimals\n",
        "X_train = torch.FloatTensor(X_train)\n",
        "X_test = torch.FloatTensor(X_test)\n",
        "# These lines convert your NumPy arrays X_train and X_test into PyTorch tensors of type FloatTensor.\n",
        "\n",
        "# convert y labels to tensors long\n",
        "# long tensors are 64 bit integers (because we want the species thing to be int)\n",
        "y_train = torch.LongTensor(y_train)\n",
        "y_test = torch.LongTensor(y_test)\n",
        "# torch.LongTensor is used for tensors containing 64-bit integer numbers. In your case, your labels (y)\n",
        "# represent discrete classes (0, 1, 2) after you replaced the string species names with integers. When\n",
        "# working with classification tasks and loss functions like nn.CrossEntropyLoss (which you use later),\n",
        "# the target labels are typically expected to be integer types, specifically LongTensor.\n",
        "\n",
        "# PyTorch supports various tensor types to accommodate different kinds of data and computational needs. Here are some common ones besides FloatTensor and LongTensor:\n",
        "# torch.BoolTensor: Tensors containing boolean values (True or False). Useful for masking and logical operations.\n",
        "# torch.DoubleTensor: Tensors containing 64-bit floating-point numbers (also known as torch.float64). Offers higher precision than FloatTensor but uses more memory and can be slower."
      ],
      "metadata": {
        "id": "MQ3OCwkGXPd1"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set the criterion of model to measure the error, how far off the predictions are from the data\n",
        "criterion = nn.CrossEntropyLoss() #function we use for this model\n",
        "# The criterion, or loss function, is a mathematical function that measures the difference between the model's predictions and the actual target values. It quantifies how \"wrong\" your model's predictions are.\n",
        "# nn.CrossEntropyLoss(): This is the specific loss function you are using. It's a very common choice for multi-class classification problems like the Iris dataset (where you are classifying flowers into one of three species). It combines two steps:\n",
        "# It calculates the softmax activation on the model's output (converting the raw output scores into probabilities that sum up to 1 across the classes).\n",
        "# It then calculates the negative log-likelihood of the true class given the predicted probabilities. This penalizes the model more heavily when it assigns a low probability to the correct class.\n",
        "\n",
        "# The choice of loss function depends heavily on the type of problem you are trying to solve:\n",
        "# nn.MSELoss() (Mean Squared Error Loss): Commonly used for regression problems, where the goal is to predict a continuous numerical value. It calculates the average of the squared differences between the predicted and actual values.\n",
        "# nn.BCELoss() (Binary Cross Entropy Loss): Used for binary classification problems (two classes). It measures the difference between two probability distributions. Often used with a sigmoid activation in the output layer.\n",
        "# nn.BCEWithLogitsLoss(): Similar to BCELoss but is more numerically stable and should be used when the model's output is raw scores (logits) without a sigmoid activation.\n",
        "# nn.L1Loss() (Mean Absolute Error Loss): Another option for regression, calculating the average of the absolute differences between predictions and actuals. Less sensitive to outliers than MSELoss.\n",
        "# Custom Loss Functions: You can also define your own custom loss function if none of the standard ones fit your specific problem requirements.\n",
        "\n",
        "#choose optimizer (adam optimizer) and set our learning rate = learning rate (if error doesn't go down after a bunch of iterations (epochs), lower our learning rate)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 0.01) #lr - learning rate\n",
        "# the lower the learning rate, the more time the model will take to learn\n",
        "\n",
        "# The optimizer is an algorithm that adjusts the model's parameters (weights and biases) during training in order to minimize the loss function. It determines how the model learns from the error signal provided by the loss function.\n",
        "# torch.optim.Adam: This specifies that you are using the Adam optimizer. Adam is a popular and generally effective optimization algorithm that adapts the learning rate for each parameter individually based on estimates of first and second moments of the gradients.\n",
        "# model.parameters(): This tells the optimizer which parameters it should update. model.parameters() is a method that returns an iterator over all the learnable parameters (weights and biases) in your Model instance.\n",
        "# lr = 0.01: This sets the learning rate. The learning rate is a hyperparameter that controls how large of a step the optimizer takes in the direction of the negative gradient during each update. A higher learning rate means larger steps, which can lead to faster\n",
        "# convergence but might overshoot the minimum. A lower learning rate means smaller steps, which can be slower but might help the optimizer find a better minimum. Choosing an appropriate learning rate is crucial for effective training.\n",
        "\n",
        "# There are many other optimization algorithms available in torch.optim:\n",
        "# torch.optim.SGD() (Stochastic Gradient Descent): A fundamental optimizer. It updates parameters based on the gradient of the loss for a small batch of data. Can be slow but is well-understood. Often used with momentum.\n",
        "# torch.optim.Adagrad(): Adapts the learning rate to the parameters, but the learning rate tends to decrease over time.\n",
        "# torch.optim.RMSprop(): Similar to Adagrad but with a different way of scaling the learning rate."
      ],
      "metadata": {
        "id": "8SNDwiORYUDI"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train our model\n",
        "# define how many epochs we want (epoch - run thru all the training data in our network)\n",
        "epochs = 100\n",
        "# we want to track our error\n",
        "losses = []\n",
        "\n",
        "for i in range(epochs):\n",
        "  # go forward and get a prediction\n",
        "  y_pred = model.forward(X_train) # get predicted results\n",
        "\n",
        "  # measure the loss/error, will be high in the beginning\n",
        "  loss = criterion(y_pred, y_train) # predicted value Vs y_train value\n",
        "\n",
        "  # keep track of our losses\n",
        "  losses.append(loss.detach().numpy()) # we do that because loss is a tensor and we want to convert it\n",
        "  # This line is used to record the value of the loss at the end of each training epoch. Let's break it down step by step:\n",
        "  # loss: This is the loss variable you calculated using criterion(y_pred, y_train). In PyTorch, when you calculate a loss using a criterion on tensors that require gradients, the resulting loss variable is also a PyTorch tensor that is part of the computation graph. This means PyTorch is keeping track of how this loss was computed from the model's parameters, which is necessary for backpropagation.\n",
        "  # .detach(): This is a method called on a PyTorch tensor. When you call .detach() on a tensor that is part of a computation graph, it creates a new tensor that has the same data but is detached from the graph. This means that no gradients will be calculated for this new tensor during the backward pass.\n",
        "  # Why detach?: You want to store the loss value for plotting or analysis, but you don't want the process of appending the loss to the losses list to be part of the gradient calculation during backpropagation. Detaching the tensor prevents gradients from flowing back through this operation.\n",
        "  # .numpy(): This is a method called on a PyTorch tensor (after it has been detached). It converts the PyTorch tensor into a NumPy array.\n",
        "  # Why numpy?: The losses list is a standard Python list, and you want to append a simple numerical value to it, not a PyTorch tensor (especially one that is part of a computation graph). Converting the detached tensor to a NumPy array gives you a standard numerical value that can be easily stored in a Python list and used later for plotting with Matplotlib (which works well with NumPy arrays).\n",
        "\n",
        "  # print every 10 epochs\n",
        "  if i % 10 == 0:\n",
        "    print(f'Epoch: {i}, loss: {loss}')\n",
        "\n",
        "  # do some back propogation: take the error rate of forward propagation and feed it back through the network to fine tune the weights\n",
        "  optimizer.zero_grad()\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  # optimizer.zero_grad(): This line clears the gradients of all optimized tensors. Gradients are calculated during the backward pass (loss.backward()) and accumulate by default. Before calculating the gradients for the current epoch, you need to zero them out to prevent them from mixing with the gradients from previous epochs.\n",
        "  # loss.backward(): This is the backpropagation step. It calculates the gradient of the loss with respect to each parameter in your model (model.parameters()). These gradients indicate how much each parameter needs to change to reduce the loss.\n",
        "  # optimizer.step(): This line updates the model's parameters using the gradients computed in the backward pass and the chosen optimization algorithm (Adam in your case). The optimizer adjusts the weights and biases of the network based on the learning rate and the calculated gradients, moving the model towards a state that minimizes the loss.\n",
        "  # In essence, this block of code does the following in each epoch:\n",
        "  # Clears old gradients.\n",
        "  # Calculates new gradients based on the current loss.\n",
        "  # Updates the model's parameters using the calculated gradients to improve its performance."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PGU5uF2cZbUE",
        "outputId": "5130b584-21e7-4269-f09c-144f121971b6"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0, loss: 1.1251550912857056\n",
            "Epoch: 10, loss: 1.0096259117126465\n",
            "Epoch: 20, loss: 0.8512223958969116\n",
            "Epoch: 30, loss: 0.654869019985199\n",
            "Epoch: 40, loss: 0.44905662536621094\n",
            "Epoch: 50, loss: 0.2707386612892151\n",
            "Epoch: 60, loss: 0.15461841225624084\n",
            "Epoch: 70, loss: 0.09299226105213165\n",
            "Epoch: 80, loss: 0.06447023898363113\n",
            "Epoch: 90, loss: 0.050585027784109116\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# graph it out\n",
        "plt.plot(range(epochs), losses)\n",
        "plt.ylabel('loss/error')\n",
        "plt.xlabel('epoch')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "x3u948L4ct-o",
        "outputId": "ecec609a-3d0d-4512-f6aa-87d8ae456e61"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'epoch')"
            ]
          },
          "metadata": {},
          "execution_count": 33
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate Model on Test Data Set\n",
        "\n",
        "with torch.no_grad(): # this turns off back propogation\n",
        "# code block indented under with torch.no_grad(): will be executed with gradient tracking disabled.\n",
        "# Why use it: During training, PyTorch automatically builds a computation graph to track operations and calculate gradients for backpropagation (loss.backward()). However, during evaluation or inference (when you're just using the trained model to make predictions), you don't need to calculate gradients because you're not updating the model's parameters.\n",
        "  y_eval = model.forward(X_test) # X_test are features from our test set, y_eval will be predictions\n",
        "  loss = criterion(y_eval, y_test) # find loss/error\n",
        "\n",
        "loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-X1QgEYjOmUB",
        "outputId": "99933877-e405-4df5-b9bd-56cf1f19cab1"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.1296)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "with torch.no_grad():\n",
        "  for i, data in enumerate(X_test):\n",
        "  # The enumerate() function provides both the index (i) and the value (data) for each item in X_test.\n",
        "  # What i represents: i is the index of the current data sample being processed in the loop (starting from 0).\n",
        "  # What data represents: data is a single data sample (a row of features) from the X_test tensor. In this case, it's a tensor containing the four features (sepal length, sepal width, petal length, petal width) for one iris flower.\n",
        "    y_val = model.forward(data)\n",
        "    # y_val is a PyTorch tensor containing the model's raw output scores (logits) for the current single data sample. For the Iris dataset with 3 classes, y_val will be a tensor with 3 elements, where each element corresponds to the model's score for one of the three species.\n",
        "\n",
        "    print(f'{i+1}.) {str(y_val)} \\t {y_test[i]} \\t {y_val.argmax().item()}') # this will tell us what type of flower our network thinks it is\n",
        "    # y_val.argmax().item(): This part determines the model's predicted class:\n",
        "    # y_val.argmax(): Finds the index of the highest value in the y_val tensor. Since y_val has scores for each class, the index of the highest score corresponds to the class the model predicts with the highest confidence.\n",
        "    # .item(): Converts the resulting single-element tensor from argmax() into a standard Python number (integer).\n",
        "\n",
        "    # correct or not\n",
        "    if y_val.argmax().item() == y_test[i]:\n",
        "      correct += 1\n",
        "\n",
        "print(f'we got {correct} correct')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QoT6hcW3Pvff",
        "outputId": "7c50e008-81c1-4110-aab8-75b00ef37062"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.) tensor([0.0000, 7.4818, 9.9517]) \t 2 \t 2\n",
            "2.) tensor([ 0.0000,  7.7416, 14.4150]) \t 2 \t 2\n",
            "3.) tensor([ 0.0000,  9.1741, 15.2260]) \t 2 \t 2\n",
            "4.) tensor([0.2420, 8.3711, 4.5725]) \t 1 \t 1\n",
            "5.) tensor([ 0.0000,  8.4455, 12.5213]) \t 2 \t 2\n",
            "6.) tensor([1.6580, 8.0895, 2.0248]) \t 1 \t 1\n",
            "7.) tensor([0.0000, 8.1067, 9.3146]) \t 2 \t 2\n",
            "8.) tensor([0.3616, 8.4538, 4.3424]) \t 1 \t 1\n",
            "9.) tensor([ 0.0000,  8.2780, 10.8831]) \t 2 \t 2\n",
            "10.) tensor([ 0.0000,  8.2340, 15.2944]) \t 2 \t 2\n",
            "11.) tensor([0.0000, 8.0207, 8.7722]) \t 2 \t 2\n",
            "12.) tensor([9.0044, 3.5022, 0.0000]) \t 0 \t 0\n",
            "13.) tensor([8.0835, 3.2078, 0.0000]) \t 0 \t 0\n",
            "14.) tensor([2.2655, 6.5108, 0.4715]) \t 1 \t 1\n",
            "15.) tensor([8.0545, 3.9531, 0.0000]) \t 0 \t 0\n",
            "16.) tensor([0.0000, 8.1667, 8.0483]) \t 2 \t 1\n",
            "17.) tensor([8.3930, 3.3382, 0.0000]) \t 0 \t 0\n",
            "18.) tensor([0.0000, 7.6729, 9.5912]) \t 1 \t 2\n",
            "19.) tensor([8.6390, 3.3854, 0.0000]) \t 0 \t 0\n",
            "20.) tensor([7.5293, 3.3366, 0.0000]) \t 0 \t 0\n",
            "21.) tensor([2.0055, 7.1311, 1.1164]) \t 1 \t 1\n",
            "22.) tensor([ 0.0000,  8.4883, 14.0726]) \t 2 \t 2\n",
            "23.) tensor([8.1567, 3.8903, 0.0000]) \t 0 \t 0\n",
            "24.) tensor([8.5490, 3.3566, 0.0000]) \t 0 \t 0\n",
            "25.) tensor([2.2127, 7.3726, 0.9854]) \t 1 \t 1\n",
            "26.) tensor([1.5474, 7.7927, 2.0080]) \t 1 \t 1\n",
            "27.) tensor([0.0904, 8.6654, 5.1097]) \t 1 \t 1\n",
            "28.) tensor([1.8128, 7.5533, 1.5818]) \t 1 \t 1\n",
            "29.) tensor([8.8967, 3.4678, 0.0000]) \t 0 \t 0\n",
            "30.) tensor([0.0000, 8.2507, 5.3960]) \t 1 \t 1\n",
            "we got 28 correct\n"
          ]
        }
      ]
    }
  ]
}